# -*- coding: utf-8 -*-
"""MNIST_FUNCTIONAL_MLP AND CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wTpgky_ZIGDAXltKIef4T3tEsFDKr4ls

MLP and CNN ON MNIST DATASET

USING FUNCTIONAL MODEL

#MLP FUNCTIONAL MODEL
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.datasets import mnist
from matplotlib import pyplot as plt

# load data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

fig,axs = plt.subplots(3, 3)
cnt = 0
for i in range(3):
     for j in range(3):
       axs[i, j].imshow(x_train[cnt], cmap='gray_r')
       cnt += 1

# one-hot encoding
num_labels = len(np.unique(y_train))

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# image dimensions (assumed square)
image_size = x_train.shape[1]
input_size = image_size * image_size
print(input_size)

# resize and normalize
x_train = np.reshape(x_train, [-1, input_size])
x_train = x_train.astype('float32') / 255
x_test = np.reshape(x_test, [-1, input_size])
x_test = x_test.astype('float32') / 255

# network parameters
batch_size = 128
hidden_units = 256
dropout = 0.45

#from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model
#inp=(28,28)
input_layer=Input (shape=(28*28), )
#input_layer=Input(shape=inp)
x= Dense(56, activation='relu') (input_layer)
x= Dense(112, activation='relu')(x)
x= Dense (240, activation='relu') (x)
x=Dense(150, activation='relu') (x)
x=Dense(10, activation='softmax') (x)
model=Model (input_layer, x)
model.summary()

model.summary()
plot_model(model, to_file='mlp-mnist.png', show_shapes=True)

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

# train the network
model.fit(x_train, y_train, epochs=10, batch_size=batch_size)

# validate the model on test dataset to determine generalization
_, acc = model.evaluate(x_test,y_test,batch_size=batch_size,verbose=0)
print("\nTest accuracy: %.1f%%" % (100.0 * acc))

"""#CNN FUNCTIONAL MODEL"""

import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model

# load data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# one-hot encoding
num_labels = len(np.unique(y_train))
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# reshaping and normalising
image_size = x_train.shape[1]
x_train = np.reshape(x_train,[-1, image_size, image_size, 1])
x_test = np.reshape(x_test,[-1, image_size, image_size, 1])
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

input_shape = (image_size, image_size, 1) #(28,28,1)
batch_size = 128
kernel_size = 3
filters = 64
dropout = 0.3

inputs = Input(shape=input_shape)#  input_shape=(28,28,1)
y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs)
y = MaxPooling2D()(y)
y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)
y = MaxPooling2D()(y)
y = Conv2D(filters=filters,kernel_size=kernel_size,activation='relu')(y)
# flattening = convert image to vector 
y = Flatten()(y)
# dropout regularization
y = Dropout(dropout)(y)
outputs = Dense(num_labels, activation='softmax')(y)
# model building by supplying inputs/outputs
model = Model(inputs=inputs, outputs=outputs)

model.summary()
plot_model(model, to_file='mlp-mnist.png', show_shapes=True)

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(x_train,y_train,validation_data=(x_test, y_test),epochs=5,batch_size=batch_size)

# validate the model on test dataset to determine generalization
_, acc = model.evaluate(x_test,y_test,batch_size=batch_size,verbose=0)
print("\nTest accuracy: %.1f%%" % (100.0 * acc))


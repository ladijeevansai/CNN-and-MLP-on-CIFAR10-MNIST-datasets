# -*- coding: utf-8 -*-
"""MLP_MNIST_sequential_AND_functional api

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lovPE47kc9pt-95kAhAMuUOnl472WzWP

MLP ON MNIST DATASET

USING SEQUENTIAL AND FUNCTIONAL MODELS

##Using Sequential MODEL
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.datasets import mnist

#loading the mnist dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#one-hot encoding
num_labels = len(np.unique(y_train))
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

#calculating input shape
image_size = x_train.shape[1]
input_size = image_size * image_size
print(input_size)

#reshaping 
x_train = np.reshape(x_train, [-1, input_size])
x_train = x_train.astype('float32') / 255
x_test = np.reshape(x_test, [-1, input_size])
x_test = x_test.astype('float32') / 255

batch_size = 128
hidden_units = 256
dropout = 0.45

model = Sequential()
model.add(Dense(hidden_units, input_dim=input_size))
model.add(Activation('relu'))
model.add(Dropout(dropout))
model.add(Dense(hidden_units))
model.add(Activation('relu'))
#model.add(Dropout(dropout))
model.add(Dense(num_labels))
# this is the output for one-hot vector
model.add(Activation('softmax'))
model.summary()
plot_model(model, to_file='mlp-mnist.png', show_shapes=True)

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
# train the network
model.fit(x_train, y_train, epochs=5, batch_size=batch_size)

# accuracy evaluation
score = model.evaluate(x_test,y_test,batch_size=batch_size,verbose=0)
print("nTest accuracy: %.1f%%" % (100.0 * score[1]))

"""##Using Functional API"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.datasets import mnist

# load data
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# one-hot encoding
num_labels = len(np.unique(y_train))
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# reshaping and normalising
image_size = x_train.shape[1]
x_train = np.reshape(x_train,[-1, image_size, image_size, 1])
x_test = np.reshape(x_test,[-1, image_size, image_size, 1])
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

input_shape = (image_size, image_size, 1) #(28,28,1)
batch_size = 128
kernel_size = 3
filters = 64
dropout = 0.3

inputs = Input(shape=input_shape)#  input_shape=(28,28,1)
y = Conv2D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs)
y = MaxPooling2D()(y)
y = Conv2D(filters=filters,kernel_size=kernel_size,
activation='relu')(y)
y = MaxPooling2D()(y)
y = Conv2D(filters=filters,kernel_size=kernel_size,
activation='relu')(y)
# flattening = convert image to vector 
y = Flatten()(y)
# dropout regularization
y = Dropout(dropout)(y)
outputs = Dense(num_labels, activation='softmax')(y)
# model building by supplying inputs/outputs
model = Model(inputs=inputs, outputs=outputs)

model.summary()
plot_model(model, to_file='mlp-mnist.png', show_shapes=True)

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(x_train,y_train,validation_data=(x_test, y_test),epochs=5,batch_size=batch_size)

score = model.evaluate(x_test,y_test,batch_size=batch_size,verbose=0)
print("nTest accuracy: %.1f%%" % (100.0 * score[1]))

